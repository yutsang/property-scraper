{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Areas: 100%|██████████| 53/53 [17:50<00:00, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping complete. All data saved in: 2025-04-13_centanet_ici_transaction.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import urllib.parse\n",
    "import os\n",
    "from fake_useragent import UserAgent\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# Configuration\n",
    "DEFAULT_START_DATE = \"2010-01-01\"\n",
    "DEFAULT_END_DATE = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "AREA_CODE_FILE = \"Centanet_ICI_Area_Code.xlsx\"\n",
    "BASE_URL = \"https://oir.centanet.com/api/Transaction/GetTransactionList\"\n",
    "PAGESIZE = 10000\n",
    "\n",
    "def get_random_user_agent():\n",
    "    ua = UserAgent()\n",
    "    return ua.random\n",
    "\n",
    "def get_cookies():\n",
    "    # This is a placeholder. In a real scenario, you'd implement a way to get fresh cookies.\n",
    "    return {\n",
    "        \"cookie1\": f\"value1_{random.randint(1000, 9999)}\",\n",
    "        \"cookie2\": f\"value2_{random.randint(1000, 9999)}\"\n",
    "    }\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retry = Retry(total=3, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        start_dt = datetime.datetime.strptime(DEFAULT_START_DATE, \"%Y-%m-%d\")\n",
    "        end_dt = datetime.datetime.strptime(DEFAULT_END_DATE, \"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing dates:\", e)\n",
    "        return\n",
    "\n",
    "    start_api = start_dt.strftime(\"%d/%m/%Y\")\n",
    "    end_api = end_dt.strftime(\"%d/%m/%Y\")\n",
    "    date_range = f\"{start_api}-{end_api}\"\n",
    "    date_range_encoded = urllib.parse.quote(date_range)\n",
    "\n",
    "    try:\n",
    "        area_df = pd.read_excel(AREA_CODE_FILE, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {AREA_CODE_FILE}:\", e)\n",
    "        return\n",
    "\n",
    "    output_file = f\"{datetime.date.today().strftime('%Y-%m-%d')}_centanet_ici_transaction.csv\"\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    session = create_session()\n",
    "    cookies = get_cookies()\n",
    "\n",
    "    for idx, row in tqdm(area_df.iterrows(), total=area_df.shape[0], desc=\"Processing Areas\"):\n",
    "        if idx % 10 == 0:\n",
    "            cookies = get_cookies()\n",
    "            session = create_session()\n",
    "\n",
    "        region = row[\"Region\"]\n",
    "        district = row[\"District\"]\n",
    "        code = row[\"Code\"]\n",
    "\n",
    "        #print(f\"\\nProcessing area: {district} (Code: {code}, Region: {region})\")\n",
    "        page_index = 1\n",
    "        area_results = []\n",
    "\n",
    "        while True:\n",
    "            url = (f\"{BASE_URL}?pageindex={page_index}&pagesize={PAGESIZE}\"\n",
    "                   f\"&daterang={date_range_encoded}&posttype=B&districtids={code}&lang=EN\")\n",
    "            \n",
    "            headers = {\n",
    "                \"User-Agent\": get_random_user_agent(),\n",
    "                \"Accept\": \"application/json, text/plain, */*\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "                \"Referer\": \"https://oir.centanet.com/\",\n",
    "                \"Origin\": \"https://oir.centanet.com\",\n",
    "                \"Connection\": \"keep-alive\"\n",
    "            }\n",
    "\n",
    "            #print(f\"Requesting page {page_index} for area {district} …\")\n",
    "            try:\n",
    "                response = session.get(url, headers=headers, cookies=cookies, timeout=20)\n",
    "                response.raise_for_status()\n",
    "                json_data = response.json()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(\"Error during the API request for area\", district, \":\", e)\n",
    "                break\n",
    "\n",
    "            if json_data.get(\"responseCode\") != 1:\n",
    "                print(\"API response not successful; ending pagination for\", district)\n",
    "                break\n",
    "\n",
    "            items = json_data.get(\"data\", {}).get(\"recordList\", {}).get(\"items\", [])\n",
    "            if not items:\n",
    "                #print(f\"No items found on page {page_index} for area {district}.\")\n",
    "                break\n",
    "\n",
    "            for item in items:\n",
    "                item[\"Region\"] = region\n",
    "                item[\"District\"] = district\n",
    "                item[\"AreaCode\"] = code\n",
    "                area_results.append(item)\n",
    "            \n",
    "            #print(f\"Fetched {len(items)} items on page {page_index} for area {district}.\")\n",
    "            page_index += 1\n",
    "\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        if area_results:\n",
    "            df_area = pd.DataFrame(area_results)\n",
    "            df_area.to_csv(output_file, mode=\"a\", index=False, header=not os.path.exists(output_file), encoding=\"utf-8-sig\")\n",
    "            #print(f\"Saved {len(area_results)} items for area {district} into {output_file}.\")\n",
    "        else:\n",
    "            print(f\"No data collected for area {district}.\")\n",
    "        \n",
    "        time.sleep(random.uniform(5, 7))\n",
    "\n",
    "    print(\"\\nScraping complete. All data saved in:\", output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/2354615037.py:4: DtypeWarning: Columns (6,16,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_clean = pd.read_csv('2025-02-27_centanet_ici_transaction.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348777, 34)\n"
     ]
    }
   ],
   "source": [
    "#simple cleansing\n",
    "import pandas as pd \n",
    "\n",
    "df_clean = pd.read_csv('2025-02-27_centanet_ici_transaction.csv')\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'price'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'price'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'pricePostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'pricePostTypeDisplayName'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'avgPrice'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgPrice'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'rental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rental'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'rentPostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rentPostTypeDisplayName'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.loc[:, 'avgRental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgRental'))\n",
      "/var/folders/rx/s42f27kn5j5ddqzlhz7qr2yw0000gn/T/ipykernel_84647/3232419267.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleansed.drop(columns=['priceInfo'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Selecting Columns, the updated shape is: (348777, 24).\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df_cleansed = df_clean[['id', 'deptDisplayName', 'centabldg', 'transactionDate', 'transactionType',\n",
    "                        'propertyNameCn', 'propertyNameEn', 'propertyUsageDisplayName','floor',\n",
    "                        'unit', 'isPriceEstimated', 'transactionArea', 'sourceDisplayName',\n",
    "                        'priceInfo', 'ibsContractID', 'addressDisplayName', 'Region', 'District',\n",
    "                        'AreaCode']]\n",
    "\n",
    "def safe_get_value(x, key, default=None):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            x = ast.literal_eval(x)\n",
    "        except (SyntaxError, ValueError):\n",
    "            return default\n",
    "    if isinstance(x, dict):\n",
    "        return x.get(key, default)\n",
    "    return default\n",
    "\n",
    "# Use .loc columns assignment on the DataFrame copy\n",
    "df_cleansed.loc[:, 'price'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'price'))\n",
    "# df_cleansed.loc[:, 'priceDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'priceDisplayName'))\n",
    "df_cleansed.loc[:, 'pricePostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'pricePostTypeDisplayName'))\n",
    "df_cleansed.loc[:, 'avgPrice'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgPrice'))\n",
    "#df_cleansed.loc[:, 'avgPriceDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgPriceDisplayName'))\n",
    "df_cleansed.loc[:, 'rental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rental'))\n",
    "# df_cleansed.loc[:, 'rentalDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rentalDisplayName'))\n",
    "df_cleansed.loc[:, 'rentPostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rentPostTypeDisplayName'))\n",
    "df_cleansed.loc[:, 'avgRental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgRental'))\n",
    "#df_cleansed.loc[:, 'avgRentalDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgRentalDisplayName'))\n",
    "#df_cleansed.loc[:, 'gains_Price'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'gains_Price'))\n",
    "#df_cleansed.loc[:, 'gains_Rental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'gains_Rental'))\n",
    "#df_cleansed.loc[:, 'priceTo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'priceTo'))\n",
    "#df_cleansed.loc[:, 'rentalTo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rentalTo'))\n",
    "#df_cleansed.loc[:, 'unitPriceTo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'unitPriceTo'))\n",
    "#df_cleansed.loc[:, 'unitRentalTo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'unitRentalTo'))\n",
    "#df_cleansed.loc[:, 'priceDesc'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'priceDesc'))\n",
    "#df_cleansed.loc[:, 'fhPriceInfo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'fhPriceInfo'))\n",
    "#df_cleansed.loc[:, 'fhAvgPriceInfo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'fhAvgPriceInfo'))\n",
    "#df_cleansed.loc[:, 'fhRentInfo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'fhRentInfo'))\n",
    "#df_cleansed.loc[:, 'fhAvgRentInfo'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'fhAvgRentInfo'))\n",
    "\n",
    "# Optionally, drop the original priceInfo containing the dictionaries\n",
    "df_cleansed.drop(columns=['priceInfo'], inplace=True)\n",
    "\n",
    "df_cleansed.to_excel('2025-02-27_centanet_ici_transaction.xlsx', index=False)\n",
    "\n",
    "print(f'After Selecting Columns, the updated shape is: {df_cleansed.shape}.')\n",
    "\t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\n",
    "#436.5MB csv -> 53.1MB xlsx -> 51MB xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt updated code - in one piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Areas:   0%|          | 0/53 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal dataframe shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_cleansed\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[43mscrape_and_clean_centanet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 123\u001b[0m, in \u001b[0;36mscrape_and_clean_centanet_data\u001b[0;34m(start_date, end_date, area_code_file)\u001b[0m\n\u001b[1;32m    120\u001b[0m         area_results\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[1;32m    122\u001b[0m     page_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 123\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m area_results:\n\u001b[1;32m    126\u001b[0m     df_area \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(area_results)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import urllib.parse\n",
    "import os\n",
    "import ast\n",
    "from fake_useragent import UserAgent\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# Configuration\n",
    "DEFAULT_START_DATE = \"2010-01-01\"\n",
    "DEFAULT_END_DATE = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "AREA_CODE_FILE = \"Centanet_ICI_Area_Code.xlsx\"\n",
    "BASE_URL = \"https://oir.centanet.com/api/Transaction/GetTransactionList\"\n",
    "PAGESIZE = 10000\n",
    "\n",
    "def get_random_user_agent():\n",
    "    ua = UserAgent()\n",
    "    return ua.random\n",
    "\n",
    "def get_cookies():\n",
    "    return {\n",
    "        \"cookie1\": f\"value1_{random.randint(1000, 9999)}\",\n",
    "        \"cookie2\": f\"value2_{random.randint(1000, 9999)}\"\n",
    "    }\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retry = Retry(total=3, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def safe_get_value(x, key, default=None):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            x = ast.literal_eval(x)\n",
    "        except (SyntaxError, ValueError):\n",
    "            return default\n",
    "    if isinstance(x, dict):\n",
    "        return x.get(key, default)\n",
    "    return default\n",
    "\n",
    "def scrape_and_clean_centanet_data(start_date=DEFAULT_START_DATE, end_date=DEFAULT_END_DATE, area_code_file=AREA_CODE_FILE):\n",
    "    try:\n",
    "        start_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_dt = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing dates:\", e)\n",
    "        return\n",
    "\n",
    "    start_api = start_dt.strftime(\"%d/%m/%Y\")\n",
    "    end_api = end_dt.strftime(\"%d/%m/%Y\")\n",
    "    date_range = f\"{start_api}-{end_api}\"\n",
    "    date_range_encoded = urllib.parse.quote(date_range)\n",
    "\n",
    "    try:\n",
    "        area_df = pd.read_excel(area_code_file, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {area_code_file}:\", e)\n",
    "        return\n",
    "\n",
    "    output_file = f\"{datetime.date.today().strftime('%Y-%m-%d')}_centanet_ici_transaction.csv\"\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    session = create_session()\n",
    "    cookies = get_cookies()\n",
    "\n",
    "    for idx, row in tqdm(area_df.iterrows(), total=area_df.shape[0], desc=\"Processing Areas\"):\n",
    "        if idx % 10 == 0:\n",
    "            cookies = get_cookies()\n",
    "            session = create_session()\n",
    "\n",
    "        region = row[\"Region\"]\n",
    "        district = row[\"District\"]\n",
    "        code = row[\"Code\"]\n",
    "\n",
    "        page_index = 1\n",
    "        area_results = []\n",
    "\n",
    "        while True:\n",
    "            url = (f\"{BASE_URL}?pageindex={page_index}&pagesize={PAGESIZE}\"\n",
    "                   f\"&daterang={date_range_encoded}&posttype=B&districtids={code}&lang=EN\")\n",
    "            \n",
    "            headers = {\n",
    "                \"User-Agent\": get_random_user_agent(),\n",
    "                \"Accept\": \"application/json, text/plain, */*\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "                \"Referer\": \"https://oir.centanet.com/\",\n",
    "                \"Origin\": \"https://oir.centanet.com\",\n",
    "                \"Connection\": \"keep-alive\"\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                response = session.get(url, headers=headers, cookies=cookies, timeout=20)\n",
    "                response.raise_for_status()\n",
    "                json_data = response.json()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(\"Error during the API request for area\", district, \":\", e)\n",
    "                break\n",
    "\n",
    "            if json_data.get(\"responseCode\") != 1:\n",
    "                print(\"API response not successful; ending pagination for\", district)\n",
    "                break\n",
    "\n",
    "            items = json_data.get(\"data\", {}).get(\"recordList\", {}).get(\"items\", [])\n",
    "            if not items:\n",
    "                break\n",
    "\n",
    "            for item in items:\n",
    "                item[\"Region\"] = region\n",
    "                item[\"District\"] = district\n",
    "                item[\"AreaCode\"] = code\n",
    "                area_results.append(item)\n",
    "            \n",
    "            page_index += 1\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        if area_results:\n",
    "            df_area = pd.DataFrame(area_results)\n",
    "            df_area.to_csv(output_file, mode=\"a\", index=False, header=not os.path.exists(output_file), encoding=\"utf-8-sig\")\n",
    "        else:\n",
    "            print(f\"No data collected for area {district}.\")\n",
    "        \n",
    "        time.sleep(random.uniform(5, 7))\n",
    "\n",
    "    print(\"\\nScraping complete. All data saved in:\", output_file)\n",
    "\n",
    "    # Data cleaning\n",
    "    df_clean = pd.read_csv(output_file)\n",
    "    \n",
    "    df_cleansed = df_clean[['id', 'deptDisplayName', 'centabldg', 'transactionDate', 'transactionType',\n",
    "                            'propertyNameCn', 'propertyNameEn', 'propertyUsageDisplayName','floor',\n",
    "                            'unit', 'isPriceEstimated', 'transactionArea', 'sourceDisplayName',\n",
    "                            'priceInfo', 'ibsContractID', 'addressDisplayName', 'Region', 'District',\n",
    "                            'AreaCode']]\n",
    "\n",
    "    df_cleansed.loc[:, 'price'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'price'))\n",
    "    df_cleansed.loc[:, 'pricePostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'pricePostTypeDisplayName'))\n",
    "    df_cleansed.loc[:, 'avgPrice'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgPrice'))\n",
    "    df_cleansed.loc[:, 'rental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rental'))\n",
    "    df_cleansed.loc[:, 'rentPostTypeDisplayName'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'rentPostTypeDisplayName'))\n",
    "    df_cleansed.loc[:, 'avgRental'] = df_cleansed['priceInfo'].apply(lambda x: safe_get_value(x, 'avgRental'))\n",
    "\n",
    "    df_cleansed.drop(columns=['priceInfo'], inplace=True)\n",
    "\n",
    "    cleaned_output_file = f\"{datetime.date.today().strftime('%Y-%m-%d')}_centanet_ici_transaction_cleaned.csv\"\n",
    "    df_cleansed.to_csv(cleaned_output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f'Data cleaning complete. Cleaned data saved in: {cleaned_output_file}')\n",
    "    print(f'Final dataframe shape: {df_cleansed.shape}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_and_clean_centanet_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
