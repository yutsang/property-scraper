{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Midland ICI Transaction #1 \n",
    "# https://www.midlandici.com.hk/ics/property/transaction/json?ics_type=&date_min=2000-01-01&date_max=2025-02-12&lang=english&page_size=50000&cursor=1&order=tx_date-desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Months: 100%|██████████| 303/303 [02:28<00:00,  2.05it/s, Total Records: 316121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to all_transactions_20250330_191952.csv\n",
      "\n",
      "Total scraped transactions: 316121\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"https://www.midlandici.com.hk/ics/property/transaction/json\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\",\n",
    "    \"Referer\": \"https://www.midlandici.com.hk/\"\n",
    "}\n",
    "MAX_PAGE_SIZE = 20000  # Maximum page size allowed by API\n",
    "\n",
    "\n",
    "def generate_month_ranges(start_date, end_date):\n",
    "    \"\"\"Generate a list of month ranges (start_date to end_date).\"\"\"\n",
    "    current = end_date\n",
    "    while current >= start_date:\n",
    "        month_end = current\n",
    "        month_start = current.replace(day=1)\n",
    "        yield (month_start.strftime(\"%Y-%m-%d\"), month_end.strftime(\"%Y-%m-%d\"))\n",
    "        current = month_start - relativedelta(days=1)\n",
    "\n",
    "\n",
    "def scrape_month(date_min, date_max):\n",
    "    \"\"\"\n",
    "    Scrape data for a given month using cursor-based pagination.\n",
    "    \n",
    "    Args:\n",
    "        date_min (str): Start date in YYYY-MM-DD format.\n",
    "        date_max (str): End date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of transaction data for the given month.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    cursor = 1\n",
    "\n",
    "    with tqdm(desc=f\"Scraping {date_min} to {date_max}\", leave=False) as pbar:\n",
    "        while True:\n",
    "            params = {\n",
    "                \"ics_type\": \"\",\n",
    "                \"date_min\": date_min,\n",
    "                \"date_max\": date_max,\n",
    "                \"lang\": \"english\",\n",
    "                \"page_size\": MAX_PAGE_SIZE,\n",
    "                \"cursor\": cursor,\n",
    "                \"order\": \"tx_date-desc\"\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                if not data.get('transactions'):\n",
    "                    break\n",
    "\n",
    "                all_results.extend(data['transactions'])\n",
    "                pbar.total = data.get('count')\n",
    "                pbar.update(len(data['transactions']))\n",
    "                pbar.set_postfix_str(f\"Cursor {cursor} | Total {len(all_results)}\")\n",
    "\n",
    "                # Stop if we've reached the expected total or no more results\n",
    "                if len(all_results) >= data.get('count', 0) or len(data['transactions']) < MAX_PAGE_SIZE:\n",
    "                    break\n",
    "\n",
    "                cursor += 1\n",
    "                time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "            except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "                print(f\"Error: {e}. Retrying...\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    Save scraped data to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries containing transaction data.\n",
    "        filename (str): Name of the output CSV file.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8-sig', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "\n",
    "def scrape_all_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Scrape all transaction data between start_date and end_date.\n",
    "\n",
    "    Args:\n",
    "        start_date (datetime): Start date for scraping.\n",
    "        end_date (datetime): End date for scraping.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of all transaction data scraped.\n",
    "    \"\"\"\n",
    "    all_transactions = []\n",
    "    months = list(generate_month_ranges(start_date, end_date))\n",
    "\n",
    "    with tqdm(months, desc=\"Processing Months\") as month_pbar:\n",
    "        for date_min, date_max in month_pbar:\n",
    "            month_data = scrape_month(date_min, date_max)\n",
    "            all_transactions.extend(month_data)\n",
    "            month_pbar.set_postfix_str(f\"Total Records: {len(all_transactions)}\")\n",
    "\n",
    "    return all_transactions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the scraping range\n",
    "    START_DATE = datetime(2000, 1, 1)\n",
    "    END_DATE = datetime.now()\n",
    "\n",
    "    # Scrape all data within the range and save final output\n",
    "    all_data = scrape_all_data(START_DATE, END_DATE)\n",
    "\n",
    "    # Save final consolidated file\n",
    "    final_filename = f\"midlandici_all_transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    save_to_csv(all_data, final_filename)\n",
    "\n",
    "    print(f\"\\nTotal scraped transactions: {len(all_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
