{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current version: 133.0.6943.127\n",
    "#sudo rm /usr/local/bin/chromedriver\n",
    "#download chromedriver: npx @puppeteer/browsers install chrome@133.0.6943.127\n",
    "#or most updated channel: npx @puppeteer/browsers install chrome@stable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Areas: 100%|██████████| 178/178 [32:01<00:00, 10.80s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import chromedriver_autoinstaller\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Utility Functions\n",
    "def generate_session_id(length=10):\n",
    "    \"\"\"Generate a random session ID consisting of lowercase letters and digits.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "def clean_subdistrict(subdistrict):\n",
    "    \"\"\"\n",
    "    Clean the subdistrict string to generate a URL-friendly slug.\n",
    "    Any sequence of non-alphanumeric characters is replaced by a hyphen.\n",
    "    The result is lowercased and stripped of extra hyphens.\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'[^A-Za-z0-9]+', '-', subdistrict)\n",
    "    return cleaned.strip('-').lower()\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"Initializes ChromeDriver with custom options including headless mode.\"\"\"\n",
    "    chromedriver_autoinstaller.install()  # Automatically installs the correct ChromeDriver version\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.6943.127 Safari/537.36\")\n",
    "    options.add_argument(\"--ignore-certificate-errors\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--headless\")  # Enable headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def scroll_down(driver, delay=5):\n",
    "    \"\"\"Scrolls down to the bottom of the page and waits for lazy-loaded content.\"\"\"\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "def extract_data(driver, control_date_dt):\n",
    "    \"\"\"\n",
    "    Extracts listing data from the current page.\n",
    "    For each row, returns:\n",
    "      [Date, Address, Price, PriceTag, Area, Ft_Price, Agency]\n",
    "    Only rows with a date newer or equal to control_date_dt are kept.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        tbody = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.bx--structured-list-tbody\"))\n",
    "        )\n",
    "        rows = tbody.find_elements(By.CSS_SELECTOR, \"div.cv-structured-list-item\")\n",
    "        \n",
    "        for row in rows:\n",
    "            try:\n",
    "                cells = row.find_elements(By.CSS_SELECTOR, \"div.cv-structured-list-data\")\n",
    "                if len(cells) >= 8:\n",
    "                    # Extract Date from cell 0.\n",
    "                    date_text = cells[0].find_element(By.CSS_SELECTOR, \"div.info-date span\").text.strip()\n",
    "                    # Extract Address from cell 1.\n",
    "                    address = cells[1].text.strip()\n",
    "                    # Extract Price from cell 3 and assign PriceTag (\"S\" for tranPrice, \"L\" for tranRent\").\n",
    "                    try:\n",
    "                        price_text = cells[3].find_element(By.CSS_SELECTOR, \"span.tranPrice\").text.strip()\n",
    "                        price_tag = \"S\"\n",
    "                    except Exception:\n",
    "                        price_text = cells[3].find_element(By.CSS_SELECTOR, \"span.tranRent\").text.strip()\n",
    "                        price_tag = \"L\"\n",
    "                    # Extract Saleable Area from cell 5.\n",
    "                    area = cells[5].text.strip()\n",
    "                    # Extract Unit Price from cell 6.\n",
    "                    ft_price = cells[6].text.strip()\n",
    "                    # Extract Agency from cell 7 (try label01 then label).\n",
    "                    try:\n",
    "                        agency = cells[7].find_element(By.CSS_SELECTOR, \"span.label01\").text.strip()\n",
    "                    except Exception:\n",
    "                        agency = cells[7].find_element(By.CSS_SELECTOR, \"span.label\").text.strip()\n",
    "                    \n",
    "                    # Parse the row date and skip if older than control date.\n",
    "                    try:\n",
    "                        row_date_dt = datetime.strptime(date_text, \"%Y-%m-%d\")\n",
    "                    except Exception:\n",
    "                        row_date_dt = None\n",
    "                    if row_date_dt and row_date_dt < control_date_dt:\n",
    "                        continue\n",
    "\n",
    "                    data.append([date_text, address, price_text, price_tag, area, ft_price, agency])\n",
    "            except Exception as row_err:\n",
    "                pass  # Ignore row extraction errors\n",
    "    except Exception as e:\n",
    "        pass  # Ignore table extraction errors\n",
    "    return data\n",
    "\n",
    "def execute_scraper():\n",
    "    # Base URL for the live site.\n",
    "    base_url = \"https://hk.centanet.com/findproperty/en/list/transaction\"\n",
    "    \n",
    "    # Set the control date (YYYY-MM-DD); adjust this value as needed.\n",
    "    control_date = \"2025-01-03\"\n",
    "    control_date_dt = datetime.strptime(control_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Read the area codes file (ensure the file is UTF-8 friendly).\n",
    "    try:\n",
    "        area_df = pd.read_excel(\"Centanet_Res_Area_Code.xlsx\", engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(\"Error reading Centanet_Res_Area_Code.xlsx:\", e)\n",
    "        return\n",
    "    \n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    # Incremental saving: define the output file.\n",
    "    file_path = f\"{datetime.today().strftime('%Y-%m-%d')}_centanet_res.csv\"\n",
    "    # Remove existing file if exists to start fresh.\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Process each row of the area codes file.\n",
    "        pbar = tqdm(total=len(area_df), desc=\"Processing Areas\", file=sys.stderr)\n",
    "        for idx, row in area_df.iterrows():\n",
    "            region = row[\"Region\"]\n",
    "            district = row[\"District\"]\n",
    "            subdistrict = row[\"Subdistrict\"]\n",
    "            code = row[\"Code\"]\n",
    "\n",
    "            # Clean the subdistrict string for URL formation.\n",
    "            subdistrict_part = clean_subdistrict(subdistrict)\n",
    "            session_id = generate_session_id()  # Generate a new session id.\n",
    "            area_url = f\"{base_url}/{subdistrict_part}_19-{code}?q={session_id}\"\n",
    "            \n",
    "            driver.get(area_url)\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.bx--structured-list-tbody\"))\n",
    "            )\n",
    "            \n",
    "            area_rows = []\n",
    "            current_page = 1\n",
    "\n",
    "            while True:\n",
    "                scroll_down(driver, delay=5)\n",
    "                page_data = extract_data(driver, control_date_dt)\n",
    "                for d in page_data:\n",
    "                    # Append area info along with the constructed area URL.\n",
    "                    area_rows.append(d + [region, district, subdistrict, code, area_url])\n",
    "                if not page_data:  # No new data on this page; assume done.\n",
    "                    break\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.btn-next:not([disabled])\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    time.sleep(5)\n",
    "                    current_page += 1\n",
    "                except Exception as e:\n",
    "                    break  # No more pages or next page button not clickable; moving to next area\n",
    "            \n",
    "            if area_rows:\n",
    "                df = pd.DataFrame(area_rows,\n",
    "                                  columns=[\"Date\", \"Address\", \"Price\", \"PriceTag\", \"Area\", \"Ft_Price\", \"Agency\",\n",
    "                                           \"Region\", \"District\", \"Subdistrict\", \"Code\", \"Area_URL\"])\n",
    "                # Incremental save: append to CSV file.\n",
    "                df.to_csv(file_path, mode=\"a\", index=False, header=not os.path.exists(file_path), encoding=\"utf-8-sig\")\n",
    "            driver.delete_all_cookies()\n",
    "            time.sleep(3)\n",
    "            pbar.update(1)  # Update the progress bar manually\n",
    "        pbar.close()  # Close the progress bar\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    execute_scraper()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
