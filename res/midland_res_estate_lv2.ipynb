{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "def flatten_json(nested_json, parent_key='', sep='_'):\n",
    "    \"\"\"Flatten nested JSON structures\"\"\"\n",
    "    items = []\n",
    "    if isinstance(nested_json, list):\n",
    "        for i, element in enumerate(nested_json):\n",
    "            items.extend(flatten_json(element, f'{parent_key}{sep}{i}', sep=sep).items())\n",
    "    elif isinstance(nested_json, dict):\n",
    "        for k, v in nested_json.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, (dict, list)):\n",
    "                items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def normalize_complex_columns(df, json_columns):\n",
    "    \"\"\"Handle all JSON-like structures including nested dicts and lists\"\"\"\n",
    "    for col in json_columns:\n",
    "        # Convert string representations to Python objects\n",
    "        df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        \n",
    "        # Process each row\n",
    "        expanded_data = []\n",
    "        for idx, entry in df[col].items():\n",
    "            if isinstance(entry, (dict, list)):\n",
    "                flattened = flatten_json(entry)\n",
    "                expanded_data.append(flattened)\n",
    "            else:\n",
    "                expanded_data.append({})\n",
    "        \n",
    "        # Create DataFrame from expanded data\n",
    "        expanded_df = pd.DataFrame(expanded_data).add_prefix(f'{col}_')\n",
    "        \n",
    "        # Merge back with original DataFrame\n",
    "        df = pd.concat([df.drop(col, axis=1), expanded_df], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sample usage for Midland data\n",
    "midland_estates = pd.read_csv('midland_estates.csv')\n",
    "json_columns = ['sm_district', 'region', 'subregion', 'district', 'combined_district',\n",
    "                'int_district', 'int_sm_district', 'location', 'developer',\n",
    "                'property_stat', 'market_stat', 'index_component_estate',\n",
    "                'parent_estate']\n",
    "\n",
    "midland_normalized = normalize_complex_columns(midland_estates.copy(), json_columns)\n",
    "\n",
    "# For list-like structures (e.g., [{'id':..., 'name':...}])\n",
    "list_columns = midland_normalized.filter(regex='_\\\\d+_').columns\n",
    "for col in list_columns:\n",
    "    base_name = col.split('_0_')[0]\n",
    "    midland_normalized[base_name] = midland_normalized.filter(regex=f'^{base_name}_\\\\d+_').apply(\n",
    "        lambda x: x.dropna().to_dict() if x.notna().any() else None, axis=1\n",
    "    )\n",
    "    midland_normalized.drop(midland_normalized.filter(regex=f'^{base_name}_\\\\d+_').columns, \n",
    "                          axis=1, inplace=True)\n",
    "\n",
    "# Save normalized data\n",
    "midland_normalized.to_csv('midland_estates_lv_2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
