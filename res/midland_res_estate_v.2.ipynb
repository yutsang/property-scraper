{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing districts:   0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing districts: 100%|██████████| 130/130 [05:13<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to midland_estates.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "from requests.exceptions import RequestException\n",
    "from tqdm import tqdm\n",
    "from collections.abc import MutableMapping\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import time, random\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load district data from Excel file and drop duplicates\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.drop_duplicates(subset=['m_district_code', 'm_district'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def fetch_estates_data(district_code, limit=500):\n",
    "    \"\"\"Fetch estate data from Midland API for a given district code\"\"\"\n",
    "    base_url = \"https://data.midland.com.hk/search/v2/estates\"\n",
    "    results = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        params = {\n",
    "            \"ad\": \"true\",\n",
    "            \"lang\": \"en\",\n",
    "            \"currency\": \"HKD\",\n",
    "            \"unit\": \"feet\",\n",
    "            \"search_behavior\": \"normal\",\n",
    "            \"intsmdist_ids\": district_code,\n",
    "            \"page\": page,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0', \n",
    "            'authorization': '''Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJndWlkIjoibXItMjAyNC0xMi0wNy0tLVlWN0hKU2QxelRzOHpwVDhJNEdjdGxLcjQ1Z0l4cWhsdVp3SEdvZXVSX1o3RkU2cmh1Q1NjVVpqM1E3SXIzZWVQSmZpMy1JSSIsImF1ZCI6Im15cGFnZWFwcC1tbm5rYiIsInN1YiI6Im1yLTIwMjQtMTItMDctLS1ZVjdISlNkMXpUczh6cFQ4STRHY3RsS3I0NWdJeHFobHVad0hHb2V1Ul9aN0ZFNnJodUNTY1VaajNRN0lyM2VlUEpmaTMtSUkiLCJpYXQiOjE3MzM1NDk0MjUsImV4cCI6MTc2ODEwOTQyNSwiaXNzIjoiZGF0YS5taWRsYW5kLmNvbS5oayJ9.LOOVgc_Nw7OPNnAlB8iC1kRHL0W8UVNVa0GaJYaxTxVZtO33ZbkR64rxMHSifvZOzYr38aJENj-SDIbkq4Y75CxqMPegyBUgHtaub-Fez5qaH2W0Dz71pUdYijDG3rB4Dkbdf8k21QsHerJmOFnpryzTVnZDxv-3g8Lmjz2WUhmrqMamKox3w-T9wRJ4p_wzcJwvXWgtvxkapr3Ep0YSJy3fJsV-Nwm_QiJf2JR0V4rOAu7f-YLMSy7IYje3W-HvVqAZV2cDphg_cYnf6CpirJPu_ix2z6BtIMpYMXeSiZyZtKCHiWFNtUm6QTD2adArWtLl_NvbgcH9mhVYuWi8NcrZBdBh4c72bSNRm104oEbRb9-vb1AylH2oFkEz33xXXEAJRtbQxoQ3qZj_yoDIexrinOSlkJB50fSu98Xizv9eZstnbtzkgVjfKpOAWQFdHKennjN9Azq6yTlejDVspL7A0JsY4ZlO4HQNdkNhiOQDYypHgx8jQMm0B0rbaa0cEz1S0s43Lh01eNVBN9Is35jAWFsJIP-iLvHqXJ9d0pGoHe0N7PQk2dmLo9E5szP0U04MZxt4m9TEpJkn-0uS_ZDSVABlBU2KGIkTmuzm1VltsDhPhoNrbJBJVdxJJdublpDnVFk8aO1gFWKNzptw48ipmLfpRosynC_x3Ud6QMU'''\n",
    "        }\n",
    "        \n",
    "        try: \n",
    "            response = requests.get(base_url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'result' in data and data['result']:\n",
    "                processed_data = process_nested_data(data['result'])\n",
    "                results.extend(processed_data)\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        except RequestException as e:\n",
    "            print(f\"Stopped fetching data at page {page} for district code {district_code} due to error: {e}\")\n",
    "            break\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_nested_data(data):\n",
    "    \"\"\"Process nested structures in the raw API response\"\"\"\n",
    "    processed_records = []\n",
    "    \n",
    "    for item in data:\n",
    "        # Process amenities\n",
    "        item = process_amenities(item)\n",
    "        \n",
    "        # Process market stats\n",
    "        processed_records.extend(process_market_stats(item))\n",
    "        \n",
    "        # Remove original nested fields\n",
    "        item.pop('market_stat_monthly', None)\n",
    "        \n",
    "    return processed_records\n",
    "\n",
    "def process_amenities(record):\n",
    "    \"\"\"Expand amenities data into separate columns\"\"\"\n",
    "    if 'amenities' in record and isinstance(record['amenities'], str):\n",
    "        try:\n",
    "            amenities = ast.literal_eval(record['amenities'])\n",
    "            for idx, amenity in enumerate(amenities, 1):\n",
    "                record[f'amenity_{idx}_type'] = amenity.get('type')\n",
    "                record[f'amenity_{idx}_name'] = amenity.get('name')\n",
    "                record[f'amenity_{idx}_walking'] = amenity.get('walking_minute')\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "    record.pop('amenities', None)\n",
    "    return record\n",
    "\n",
    "def process_market_stats(record):\n",
    "    \"\"\"Expand market statistics into multiple rows\"\"\"\n",
    "    expanded = []\n",
    "    monthly_data = record.get('market_stat_monthly')\n",
    "    \n",
    "    if monthly_data and isinstance(monthly_data, str):\n",
    "        try:\n",
    "            # Clean the string representation\n",
    "            cleaned = monthly_data.replace(\"'\", '\"').replace('None', 'null')\n",
    "            monthly_stats = json.loads(cleaned)\n",
    "            \n",
    "            for stat in monthly_stats:\n",
    "                new_record = record.copy()\n",
    "                new_record.update({\n",
    "                    'monthly_date': stat.get('date'),\n",
    "                    'monthly_avg_net_ft_price': stat.get('avg_net_ft_price')\n",
    "                })\n",
    "                expanded.append(new_record)\n",
    "        except (ValueError, SyntaxError, json.JSONDecodeError) as e:\n",
    "            print(f\"Error parsing market stats: {e}\")\n",
    "            expanded.append(record)\n",
    "    else:\n",
    "        expanded.append(record)\n",
    "        \n",
    "    return expanded\n",
    "\n",
    "def process_estate_data(df):\n",
    "    \"\"\"Process estate data for all districts\"\"\"\n",
    "    all_estate_data = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing districts\"):\n",
    "        district_data = fetch_estates_data(row['m_district_code'], limit=500)\n",
    "        all_estate_data.extend(district_data)\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "    return all_estate_data\n",
    "\n",
    "def deep_flatten_json(df, column):\n",
    "    \"\"\"Recursively flatten nested JSON structures in a column\"\"\"\n",
    "    def flatten_record(record, parent_key='', sep='_'):\n",
    "        items = []\n",
    "        if isinstance(record, dict):\n",
    "            for k, v in record.items():\n",
    "                new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    items.extend(flatten_record(v, new_key, sep=sep).items())\n",
    "                else:\n",
    "                    items.append((new_key, v))\n",
    "        elif isinstance(record, list):\n",
    "            for i, item in enumerate(record):\n",
    "                items.extend(flatten_record(item, f\"{parent_key}{sep}{i}\", sep=sep).items())\n",
    "        else:\n",
    "            items.append((parent_key, record))\n",
    "        return dict(items)\n",
    "    \n",
    "    flattened = df[column].apply(lambda x: flatten_record(x) if pd.notnull(x) else {})\n",
    "    return pd.DataFrame(flattened.tolist()).add_prefix(f'{column}_')\n",
    "\n",
    "def normalize_all_columns(df):\n",
    "    \"\"\"Comprehensive normalization of all columns\"\"\"\n",
    "    # Handle JSON-like columns\n",
    "    json_columns = [\n",
    "        'sm_district', 'region', 'subregion', 'district', 'combined_district',\n",
    "        'int_district', 'int_sm_district', 'location', 'developer',\n",
    "        'property_stat', 'market_stat', 'index_component_estate', 'parent_estate'\n",
    "    ]\n",
    "    \n",
    "    for col in json_columns:\n",
    "        if col in df.columns:\n",
    "            # Convert string to dict\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: ast.literal_eval(x) \n",
    "                if isinstance(x, str) and x.strip() \n",
    "                else (x if isinstance(x, dict) else {})\n",
    "            )\n",
    "            # Recursively flatten\n",
    "            flattened = deep_flatten_json(df, col)\n",
    "            df = pd.concat([df.drop(col, axis=1), flattened], axis=1)\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_cols = [\n",
    "        'total_unit_count', 'total_block_count', 'primary_school_net',\n",
    "        'property_stat_sell_count', 'property_stat_rent_count',\n",
    "        'market_stat_ft_price', 'market_stat_net_ft_price', 'market_stat_tx_count',\n",
    "        'market_stat_net_ft_price_chg', 'market_stat_pre_net_ft_price',\n",
    "        'market_stat_ft_price_chg', 'market_stat_pre_ft_price',\n",
    "        'market_stat_total_tx_amount', 'monthly_avg_net_ft_price',\n",
    "        'index_component_estate_net_ft_price', 'index_component_estate_net_ft_price_chg'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert boolean columns\n",
    "    bool_cols = ['hos', 'show']\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(bool)\n",
    "    \n",
    "    # Convert date columns\n",
    "    date_cols = ['first_op_date', 'monthly_date']\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Clean URL columns\n",
    "    url_cols = ['url_desc', 'buy_listing_url_desc', 'rent_listing_url_desc', 'photo']\n",
    "    for col in url_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].str.replace(r'\\\\\"', '', regex=False)\n",
    "    \n",
    "    # Handle hierarchical relationships\n",
    "    if 'parent_estate_id' in df.columns:\n",
    "        df['parent_estate_id'] = df['parent_estate_id'].fillna('')\n",
    "    if 'parent_estate_name' in df.columns:\n",
    "        df['parent_estate_name'] = df['parent_estate_name'].fillna('')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main data processing pipeline\"\"\"\n",
    "    # Load and process data\n",
    "    district_df = load_data(\"midland_res_area_code.xlsx\")\n",
    "    estate_data = process_estate_data(district_df)\n",
    "    main_df = pd.DataFrame(estate_data)\n",
    "    \n",
    "    if main_df.empty:\n",
    "        print(\"No data processed\")\n",
    "        return\n",
    "    \n",
    "    # Perform comprehensive normalization\n",
    "    normalized_df = normalize_all_columns(main_df)\n",
    "    \n",
    "    # Final cleanup\n",
    "    normalized_df = normalized_df.loc[:,~normalized_df.columns.duplicated()]\n",
    "    normalized_df = normalized_df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Save results\n",
    "    normalized_df.to_csv('midland_estates.csv', index=False)\n",
    "    print(\"Data saved to midland_estates.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
